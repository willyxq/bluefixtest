{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ls\nmkdir datasets\nmkdir models\nls"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# 0 the destination of the zip files\ncomplete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\nsmall_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n\n\n# 0 define the download path of the files\nimport os\n\ndatasets_path = os.path.join('.', 'datasets')\n\ncomplete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\nsmall_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')\n\n\n# 0 Download the files\nfrom urllib.request import urlretrieve\n\nsmall_f =  urlretrieve(small_dataset_url, small_dataset_path)\ncomplete_f =  urlretrieve(complete_dataset_url, complete_dataset_path)\n\n\n# 0 tar the files.\nimport zipfile\n\nwith zipfile.ZipFile(small_dataset_path, \"r\") as z:\n    z.extractall(datasets_path)\n\nwith zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n    z.extractall(datasets_path)"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\u001b[0m\u001b[01;34mml-latest\u001b[0m/  \u001b[01;34mml-latest-small\u001b[0m/  ml-latest-small.zip  ml-latest.zip\r\n"
                }
            ], 
            "source": "ls ./datasets"
        }, 
        {
            "source": "The start of data ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "function used: take", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 1 rating: creat RDD\nsmall_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n\nsmall_ratings_raw_data = sc.textFile(small_ratings_file)\nsmall_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 26, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['userId,movieId,rating,timestamp',\n '1,31,2.5,1260759144',\n '1,1029,3.0,1260759179',\n '1,1061,3.0,1260759182',\n '1,1129,2.0,1260759185']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "small_ratings_raw_data.take(5)"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 1 filter the lines, split the words and take only the first 3 columns\nsmall_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 28, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('1', '31', '2.5'), ('1', '1029', '3.0'), ('1', '1061', '3.0')]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "small_ratings_data.take(3)"
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 29, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('1', 'Toy Story (1995)'),\n ('2', 'Jumanji (1995)'),\n ('3', 'Grumpier Old Men (1995)')]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# 1 movie: create, filter RDD\nsmall_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n\nsmall_movies_raw_data = sc.textFile(small_movies_file)\nsmall_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n\nsmall_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n    \nsmall_movies_data.take(3)"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 2  sample subset, and map\ntraining_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=123)\nvalidation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\ntest_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 32, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('1', '2193', '2.0'), ('2', '17', '5.0')]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "validation_RDD.take(2)"
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 31, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[('1', '2193'), ('2', '17')]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "validation_for_predict_RDD.take(2)"
        }, 
        {
            "source": "used RDD.join(RDD)\nused RDD.mean()", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "For rank 4 the RMSE is 0.9400020429974122\nFor rank 8 the RMSE is 0.9468288439560869\nFor rank 12 the RMSE is 0.9500950485748263\nThe best model was trained with rank 4\n"
                }
            ], 
            "source": "# 2 Fit the model, and validation to tune the hyperparameters\nfrom pyspark.mllib.recommendation import ALS\nimport math\n\nseed = 532\niterations = 10\nregularization_parameter = 0.1\nranks = [4, 8, 12]\nerrors = [0, 0, 0]\nerr = 0\ntolerance = 0.02\n\nmin_error = float('inf')\nbest_rank = -1\nbest_iteration = -1\nfor rank in ranks:\n    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n                      lambda_=regularization_parameter)\n    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    errors[err] = error\n    err += 1\n    print('For rank %s the RMSE is %s' % (rank, error))\n    if error < min_error:\n        min_error = error\n        best_rank = rank\n\nprint('The best model was trained with rank %s' % best_rank)"
        }, 
        {
            "execution_count": 37, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 37, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[((452, 1084), 3.819532706475835),\n ((30, 1084), 4.106375714282098),\n ((278, 1084), 3.4028377645187464)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "predictions.take(3)"
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 38, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[((472, 2014), (3.0, 3.864299195240666)),\n ((254, 48), (1.0, 2.368551117192621)),\n ((558, 3728), (5.0, 3.8831056163918083))]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "rates_and_preds.take(3)"
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "For testing data the RMSE is 0.937826791033363\n"
                }
            ], 
            "source": "# 2 Retrain the model based on best hyperparameter, and test data.\nmodel = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n                      lambda_=regularization_parameter)\npredictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\nrates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\nerror = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    \nprint('For testing data the RMSE is %s' % (error))"
        }, 
        {
            "source": "used RDD.count()", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "There are 26024289 recommendations in the complete dataset\n"
                }
            ], 
            "source": "# 3 Load the complete dataset file\ncomplete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\ncomplete_ratings_raw_data = sc.textFile(complete_ratings_file)\ncomplete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n\n# Parse\ncomplete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n    \nprint (\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 3 Train the complete dataset. \ntraining_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=12)\n\ncomplete_model = ALS.train(training_RDD, best_rank, seed=seed, \n                           iterations=iterations, lambda_=regularization_parameter)"
        }, 
        {
            "execution_count": 53, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "For testing data the RMSE is 0.8323818276407379\n"
                }
            ], 
            "source": "# 3 predict the test set, cal error\ntest_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n\npredictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\nrates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\nerror = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n    \nprint ('For testing data the RMSE is %s' % (error))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "There are 45843 movies in the complete dataset\n"
                }
            ], 
            "source": "# 4 Get the complete movie data set\ncomplete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\ncomplete_movies_raw_data = sc.textFile(complete_movies_file)\ncomplete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n\n# Parse\ncomplete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n\ncomplete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n    \nprint (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
        }, 
        {
            "source": "used groupbyKey", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 43, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 4 The complete rating data\ndef get_counts_and_averages(ID_and_ratings_tuple):\n    nratings = len(ID_and_ratings_tuple[1])\n    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n\nmovie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\nmovie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\nmovie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 44, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[(135168, (6, 3.1666666666666665)), (90112, (4, 2.25)), (65538, (10, 3.35))]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "movie_ID_with_avg_ratings_RDD.take(3)"
        }, 
        {
            "execution_count": 50, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
                }
            ], 
            "source": "# 4 add new user with rating data\nnew_user_ID = 0\n\n# The format of each line is (userID, movieID, rating)\nnew_user_ratings = [\n     (0,260,4), # Star Wars (1977)\n     (0,1,3), # Toy Story (1995)\n     (0,16,3), # Casino (1995)\n     (0,25,4), # Leaving Las Vegas (1995)\n     (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n     (0,335,1), # Flintstones, The (1994)\n     (0,379,1), # Timecop (1994)\n     (0,296,3), # Pulp Fiction (1994)\n     (0,858,5) , # Godfather, The (1972)\n     (0,50,4) # Usual Suspects, The (1995)\n    ]\nnew_user_ratings_RDD = sc.parallelize(new_user_ratings)\nprint ('New user ratings: %s' % new_user_ratings_RDD.take(10))"
        }, 
        {
            "source": "used RDD.union(RDD)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 51, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 5 add the new usder data for training\ncomplete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n"
        }, 
        {
            "execution_count": 52, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "New model trained in 156.166 seconds\n"
                }
            ], 
            "source": "# 5 retrain the model\nfrom time import time\n\nt0 = time()\nnew_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n                              iterations=iterations, lambda_=regularization_parameter)\ntt = time() - t0\n\nprint (\"New model trained in %s seconds\" % round(tt,3))"
        }, 
        {
            "execution_count": 53, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 5. predict the user with other movie id's.\nnew_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n# keep just those not on the ID list (thanks Lei Li for spotting the error!)\nnew_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n\n# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\nnew_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
        }, 
        {
            "execution_count": 54, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 54, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Rating(user=0, product=116688, rating=0.7348019887496817),\n Rating(user=0, product=32196, rating=2.81062170660453),\n Rating(user=0, product=138744, rating=1.964685418787016)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "new_user_recommendations_RDD.take(3)"
        }, 
        {
            "execution_count": 55, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 55, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[(147456, ((-1.2359053415947776, 'The Legend of Longwood (2014)'), 2)),\n (27648, ((1.994881058473843, 'Bright Young Things (2003)'), 171)),\n (149508, ((2.8553080789124294, 'Spellbound (2011)'), 13))]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# 5 Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\nnew_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\nnew_user_recommendations_rating_title_and_count_RDD = \\\n    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\nnew_user_recommendations_rating_title_and_count_RDD.take(3)"
        }, 
        {
            "execution_count": 56, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "new_user_recommendations_rating_title_and_count_RDD = \\\n    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
        }, 
        {
            "execution_count": 57, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "TOP recommended movies (with more than 25 reviews):\n(\"Long Night's Journey Into Day (2000)\", 4.046686099779802, 35)\n('\"Godfather', 3.9704161044057473, 57070)\n('Frozen Planet (2011)', 3.9430972328632423, 322)\n('\"Godfather: Part II', 3.9166391395755134, 36679)\n('\"Enemies of Reason', 3.908744117688372, 29)\n('Heimat - A Chronicle of Germany (Heimat - Eine deutsche Chronik) (1984)', 3.8634101999309864, 32)\n('\"Two Escobars', 3.8260847358929113, 63)\n('Planet Earth (2006)', 3.8242371733551357, 754)\n('Band of Brothers (2001)', 3.816944657598791, 284)\n('Death on the Staircase (Soup\u00e7ons) (2004)', 3.811827589033921, 95)\n('\"Not on Your Life (Verdugo', 3.8070321140775913, 26)\n('\"Lord of the Rings: The Fellowship of the Ring', 3.806566386570744, 56827)\n('Pulp Fiction (1994)', 3.788951216637552, 87901)\n('\"Lord of the Rings: The Return of the King', 3.780718221174822, 51837)\n('\"Civil War', 3.7725339426314712, 400)\n('Madagascar (2011)', 3.7720072964589506, 26)\n('Star Wars: Episode V - The Empire Strikes Back (1980)', 3.760745749456151, 61672)\n('\"Lord of the Rings: The Two Towers', 3.757791504262374, 51882)\n('Seven Samurai (Shichinin no samurai) (1954)', 3.755714784931422, 13994)\n('Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 3.7515671367987697, 28280)\n('Long Way Round (2004)', 3.7498372265286113, 38)\n('Mei and the Kittenbus (2002)', 3.7496396329657857, 35)\n('Milius (2013)', 3.747252571048023, 37)\n('\"Usual Suspects', 3.7389702744506366, 59271)\n('The Price of Gold (2014)', 3.735483130751841, 25)\n"
                }
            ], 
            "source": "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n\nprint ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n        '\\n'.join(map(str, top_movies)))"
        }, 
        {
            "execution_count": 58, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 58, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Rating(user=0, product=116688, rating=0.7348019887496817)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# 6 predict for a single movie\nmy_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\nindividual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\nindividual_movie_rating_RDD.take(1)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": 59, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# 7 save the model\nfrom pyspark.mllib.recommendation import MatrixFactorizationModel\n\nmodel_path = os.path.join('.', 'models', 'movie_lens_als')\n\n# Save and load model\nmodel.save(sc, model_path)\nsame_model = MatrixFactorizationModel.load(sc, model_path)"
        }, 
        {
            "execution_count": 60, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\u001b[0m\u001b[01;34mmovie_lens_als\u001b[0m/\r\n"
                }
            ], 
            "source": "ls models/"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}